{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenVINO optimizations for Text classification task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages needed for successful execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, default_data_collator\n",
    "from datasets import load_dataset, load_metric\n",
    "from optimum.intel.openvino import OVAutoModelForSequenceClassification\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions on conversion to OpenVINO\n",
    "We will use the OpenVINOâ„¢ Integration with Optimum module to convert the quantized text classification model to an OpenVINO model object. <br>\n",
    "For details on quantizing the model using NNCF, refer to `quantization/README.md` <md>\n",
    "We will then use Huggingface datasets and metric to evaluate the converted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'optimized_model'\n",
    "base_model_name = \"optimized_model/ov_model.xml\"\n",
    "config = AutoConfig.from_pretrained('sentence-transformers/roberta-large-nli-stsb-mean-tokens')\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/roberta-large-nli-stsb-mean-tokens')\n",
    "ov_model = OVAutoModelForSequenceClassification.from_pretrained(model_dir, config=config, num_labels=1, from_ov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    result =  tokenizer(examples['sentence1'], examples['sentence2'], padding=\"max_length\", max_length=128, truncation=True)\n",
    "    result[\"labels\"] = examples[\"similarity_score\"]\n",
    "    return result\n",
    "\n",
    "dataset = load_dataset(\"stsb_multi_mt\", name=\"en\")\n",
    "metric = load_metric('glue', 'stsb')\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "validation_dataset = dataset['test']\n",
    "val_dataloader = DataLoader(\n",
    "       validation_dataset, shuffle=True, collate_fn=default_data_collator\n",
    "    )\n",
    "\n",
    "for idx, batch in enumerate(tqdm(val_dataloader, 'Looping over the test dataset')):\n",
    "    outputs_auto = ov_model(input_ids=batch['input_ids'].numpy(), attention_mask=batch['attention_mask'].numpy())\n",
    "    predictions_ov_auto = outputs_auto[0]\n",
    "    references = batch['labels'].numpy()\n",
    "        \n",
    "    metric.add_batch(predictions=[predictions_ov_auto], references=[references])\n",
    "\n",
    "score = metric.compute()\n",
    "print(f'Metric score : {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark the converted model using the benchmark app\n",
    "The OpenVINO toolkit provides a benchmarking application to gauge the platform specific runtime performance that can be obtained under optimal configuration parameters for a given model. For more details refer to: https://docs.openvino.ai/latest/openvino_inference_engine_tools_benchmark_tool_README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Benchmark OpenVINO model using the benchmark app')\n",
    "! benchmark_app -m \"$base_model_name\" -d CPU -api async -t 10 -hint latency"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb4d065df37eb8837d29a71c37c0df1b5b5cffbae7790c0bbef4d6b86d2d3c47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('optimumtests')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
