{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenVINO optimizations for Text classification task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages needed for successful execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, default_data_collator\n",
    "from datasets import load_dataset, load_metric\n",
    "from optimum.intel.openvino import OVAutoModelForSequenceClassification\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions on conversion to OpenVINO\n",
    "We will use the OpenVINOâ„¢ Integration with Optimum module to convert the sentiment classification model to an OpenVINO model object. <br>\n",
    "We will then use Huggingface datasets and metric to evaluate the converted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "ov_model = OVAutoModelForSequenceClassification.from_pretrained(model_name, config=config, from_pt=True)\n",
    "ov_model.save_pretrained('saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess function for the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    result =  tokenizer(examples['sentence'], padding='max_length', max_length=128, truncation=True)\n",
    "    result[\"labels\"] = examples[\"label\"]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('sst2')\n",
    "metric = load_metric('f1')\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "val_dataloader = DataLoader(\n",
    "       dataset['validation'], shuffle=True, collate_fn=default_data_collator\n",
    "    )\n",
    "\n",
    "for idx, batch in enumerate(tqdm(val_dataloader, desc=\"Looping over validation data\")):\n",
    "    outputs = ov_model(input_ids=batch['input_ids'].numpy(), attention_mask=batch['attention_mask'].numpy())\n",
    "    preds = outputs[0].argmax()\n",
    "    references = batch['labels'].numpy()\n",
    "    metric.add_batch(predictions=[preds], references=[references])\n",
    "\n",
    "ov_score = metric.compute()\n",
    "print(f'Score for SST2 dataset with OV Optimum: {ov_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark the converted model using the benchmark app\n",
    "The OpenVINO toolkit provides a benchmarking application to gauge the platform specific runtime performance that can be obtained under optimal configuration parameters for a given model. For more details refer to: https://docs.openvino.ai/latest/openvino_inference_engine_tools_benchmark_tool_README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = 'saved_model/ov_model.xml'\n",
    "print('Benchmark OpenVINO model using the benchmark app')\n",
    "! benchmark_app -m \"$base_model_name\" -d CPU -api async -t 10 -hint latency"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb4d065df37eb8837d29a71c37c0df1b5b5cffbae7790c0bbef4d6b86d2d3c47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('optimumtests')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
