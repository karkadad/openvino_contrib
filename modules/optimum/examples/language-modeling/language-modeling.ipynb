{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenVINO optimizations for language modeling task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install openvino-optimum if not installed already\n",
    "! pip install openvino-optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages needed for successful execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from optimum.intel.openvino import OVAutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions on conversion to OpenVINO\n",
    "We will use the OpenVINOâ„¢ Integration with Optimum module to convert the BERT-Base, Multilingual Uncased model to an OpenVINO model object. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-multilingual-uncased'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "ov_model = OVAutoModelWithLMHead.from_pretrained(model_name, config=config, from_pt=True)\n",
    "ov_model.save_pretrained('bert-base-multilingual_OV_IR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model by comparing to the results on the HF model card: https://huggingface.co/bert-base-multilingual-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model=ov_model, tokenizer=tokenizer)\n",
    "unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark the converted model using the benchmark app\n",
    "The OpenVINO toolkit provides a benchmarking application to gauge the platform specific runtime performance that can be obtained under optimal configuration parameters for a given model. For more details refer to: https://docs.openvino.ai/latest/openvino_inference_engine_tools_benchmark_tool_README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = 'bert-base-multilingual_OV_IR/ov_model.xml'\n",
    "\n",
    "# Set the sequence length for benchmarking\n",
    "seq_len = 128\n",
    "\n",
    "print('Benchmark OpenVINO model using the benchmark app')\n",
    "! benchmark_app -m \"$base_model_name\" -d CPU -api async -t 10 -hint latency -shape [1,\"$seq_len\"]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb4d065df37eb8837d29a71c37c0df1b5b5cffbae7790c0bbef4d6b86d2d3c47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('optimumtests')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
